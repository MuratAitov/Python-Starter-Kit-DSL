{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ðŸ“Š Data Processing Template\n",
    "\n",
    "This notebook demonstrates common data processing tasks:\n",
    "- Loading CSV/Excel files\n",
    "- Data cleaning and transformation\n",
    "- Basic analysis\n",
    "- Exporting processed data\n",
    "\n",
    "Customize this template for your own data processing needs!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard imports\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "# Add src to path\n",
    "sys.path.insert(0, str(Path.cwd().parent))\n",
    "\n",
    "# Data processing\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Our modules\n",
    "from src.config import settings\n",
    "from src.utils import get_timestamp, Timer\n",
    "\n",
    "# Set visualization style\n",
    "sns.set_style(\"whitegrid\")\n",
    "plt.rcParams['figure.figsize'] = (12, 6)\n",
    "\n",
    "print(\"âœ… Imports successful!\")\n",
    "print(f\"Timestamp: {get_timestamp()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Create Sample Data\n",
    "\n",
    "For demonstration, let's create some sample data. Replace this with loading your actual data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create sample dataset\n",
    "np.random.seed(42)\n",
    "\n",
    "sample_data = pd.DataFrame({\n",
    "    'id': range(1, 101),\n",
    "    'name': [f'User_{i}' for i in range(1, 101)],\n",
    "    'age': np.random.randint(18, 70, 100),\n",
    "    'score': np.random.normal(75, 15, 100).round(1),\n",
    "    'category': np.random.choice(['A', 'B', 'C', 'D'], 100),\n",
    "    'active': np.random.choice([True, False], 100),\n",
    "    'created_at': pd.date_range('2024-01-01', periods=100, freq='D')\n",
    "})\n",
    "\n",
    "# Add some missing values\n",
    "sample_data.loc[5:10, 'score'] = np.nan\n",
    "sample_data.loc[15:20, 'category'] = np.nan\n",
    "\n",
    "print(f\"Created sample dataset with {len(sample_data)} rows\")\n",
    "sample_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Load Your Data\n",
    "\n",
    "Uncomment and modify the code below to load your actual data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Option 1: Load CSV file\n",
    "# df = pd.read_csv(settings.RAW_DATA_DIR / 'your_file.csv')\n",
    "\n",
    "# Option 2: Load Excel file\n",
    "# df = pd.read_excel(settings.RAW_DATA_DIR / 'your_file.xlsx', sheet_name='Sheet1')\n",
    "\n",
    "# Option 3: Load from URL\n",
    "# df = pd.read_csv('https://example.com/data.csv')\n",
    "\n",
    "# For this demo, use sample data\n",
    "df = sample_data.copy()\n",
    "\n",
    "print(f\"âœ… Data loaded: {len(df)} rows, {len(df.columns)} columns\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Explore Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show first few rows\n",
    "print(\"First 5 rows:\")\n",
    "display(df.head())\n",
    "\n",
    "# Basic info\n",
    "print(\"\\nDataset Info:\")\n",
    "print(f\"  Rows: {len(df)}\")\n",
    "print(f\"  Columns: {len(df.columns)}\")\n",
    "print(f\"  Memory: {df.memory_usage().sum() / 1024:.1f} KB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Column types and missing values\n",
    "print(\"Column Information:\")\n",
    "info_df = pd.DataFrame({\n",
    "    'Type': df.dtypes,\n",
    "    'Non-Null': df.count(),\n",
    "    'Null': df.isnull().sum(),\n",
    "    'Null %': (df.isnull().sum() / len(df) * 100).round(1)\n",
    "})\n",
    "display(info_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Statistical summary\n",
    "print(\"Statistical Summary:\")\n",
    "display(df.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a copy for cleaning\n",
    "df_clean = df.copy()\n",
    "\n",
    "print(\"Before cleaning:\")\n",
    "print(f\"  Rows: {len(df_clean)}\")\n",
    "print(f\"  Missing values: {df_clean.isnull().sum().sum()}\")\n",
    "\n",
    "# Handle missing values\n",
    "# Option 1: Fill with mean/median\n",
    "df_clean['score'].fillna(df_clean['score'].median(), inplace=True)\n",
    "\n",
    "# Option 2: Fill with mode (most common value)\n",
    "df_clean['category'].fillna(df_clean['category'].mode()[0], inplace=True)\n",
    "\n",
    "# Option 3: Drop rows with any missing values\n",
    "# df_clean.dropna(inplace=True)\n",
    "\n",
    "print(\"\\nAfter cleaning:\")\n",
    "print(f\"  Rows: {len(df_clean)}\")\n",
    "print(f\"  Missing values: {df_clean.isnull().sum().sum()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Data Transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add new columns\n",
    "df_clean['score_category'] = pd.cut(\n",
    "    df_clean['score'], \n",
    "    bins=[0, 60, 75, 90, 100],\n",
    "    labels=['Low', 'Medium', 'High', 'Excellent']\n",
    ")\n",
    "\n",
    "df_clean['age_group'] = pd.cut(\n",
    "    df_clean['age'],\n",
    "    bins=[0, 25, 40, 60, 100],\n",
    "    labels=['Young', 'Adult', 'Middle-aged', 'Senior']\n",
    ")\n",
    "\n",
    "# Calculate derived fields\n",
    "df_clean['score_normalized'] = (df_clean['score'] - df_clean['score'].min()) / (df_clean['score'].max() - df_clean['score'].min())\n",
    "\n",
    "print(\"âœ… New columns added:\")\n",
    "print(df_clean[['score', 'score_category', 'score_normalized', 'age', 'age_group']].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Analysis & Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group by analysis\n",
    "print(\"Average score by category:\")\n",
    "category_stats = df_clean.groupby('category')['score'].agg(['mean', 'std', 'count']).round(2)\n",
    "display(category_stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualization 1: Distribution\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Score distribution\n",
    "axes[0].hist(df_clean['score'], bins=20, edgecolor='black', alpha=0.7)\n",
    "axes[0].set_title('Score Distribution', fontsize=14, fontweight='bold')\n",
    "axes[0].set_xlabel('Score')\n",
    "axes[0].set_ylabel('Frequency')\n",
    "axes[0].axvline(df_clean['score'].mean(), color='red', linestyle='--', label='Mean')\n",
    "axes[0].legend()\n",
    "\n",
    "# Age distribution\n",
    "axes[1].hist(df_clean['age'], bins=15, edgecolor='black', alpha=0.7, color='green')\n",
    "axes[1].set_title('Age Distribution', fontsize=14, fontweight='bold')\n",
    "axes[1].set_xlabel('Age')\n",
    "axes[1].set_ylabel('Frequency')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualization 2: Category comparison\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Box plot\n",
    "df_clean.boxplot(column='score', by='category', ax=axes[0])\n",
    "axes[0].set_title('Score by Category (Box Plot)', fontsize=14, fontweight='bold')\n",
    "axes[0].set_xlabel('Category')\n",
    "axes[0].set_ylabel('Score')\n",
    "plt.suptitle('')  # Remove automatic title\n",
    "\n",
    "# Bar plot\n",
    "category_counts = df_clean['category'].value_counts()\n",
    "category_counts.plot(kind='bar', ax=axes[1], color='skyblue', edgecolor='black')\n",
    "axes[1].set_title('Category Distribution', fontsize=14, fontweight='bold')\n",
    "axes[1].set_xlabel('Category')\n",
    "axes[1].set_ylabel('Count')\n",
    "axes[1].tick_params(axis='x', rotation=0)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Save Processed Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure output directory exists\n",
    "settings.PROCESSED_DATA_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Save to CSV\n",
    "output_file = settings.PROCESSED_DATA_DIR / f'processed_data_{get_timestamp().replace(\":\", \"-\").replace(\" \", \"_\")}.csv'\n",
    "df_clean.to_csv(output_file, index=False)\n",
    "\n",
    "print(f\"âœ… Data saved to: {output_file}\")\n",
    "print(f\"   Rows: {len(df_clean)}\")\n",
    "print(f\"   Columns: {len(df_clean.columns)}\")\n",
    "print(f\"   Size: {output_file.stat().st_size / 1024:.1f} KB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Summary Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 60)\n",
    "print(\"ðŸ“Š DATA PROCESSING SUMMARY\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"\\nTimestamp: {get_timestamp()}\")\n",
    "print(f\"\\nOriginal Data:\")\n",
    "print(f\"  â€¢ Rows: {len(df)}\")\n",
    "print(f\"  â€¢ Columns: {len(df.columns)}\")\n",
    "print(f\"  â€¢ Missing values: {df.isnull().sum().sum()}\")\n",
    "print(f\"\\nProcessed Data:\")\n",
    "print(f\"  â€¢ Rows: {len(df_clean)}\")\n",
    "print(f\"  â€¢ Columns: {len(df_clean.columns)}\")\n",
    "print(f\"  â€¢ Missing values: {df_clean.isnull().sum().sum()}\")\n",
    "print(f\"\\nKey Statistics:\")\n",
    "print(f\"  â€¢ Average score: {df_clean['score'].mean():.2f}\")\n",
    "print(f\"  â€¢ Average age: {df_clean['age'].mean():.1f}\")\n",
    "print(f\"  â€¢ Active users: {df_clean['active'].sum()} ({df_clean['active'].sum()/len(df_clean)*100:.1f}%)\")\n",
    "print(f\"\\nOutput: {output_file}\")\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"âœ… Processing complete!\")\n",
    "print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ðŸ’¡ Next Steps\n",
    "\n",
    "1. **Replace sample data** with your actual dataset\n",
    "2. **Customize cleaning** logic for your needs\n",
    "3. **Add analysis** specific to your domain\n",
    "4. **Create visualizations** that tell your story\n",
    "5. **Save results** in formats you need (CSV, Excel, JSON)\n",
    "\n",
    "Happy data processing! ðŸŽ‰"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
